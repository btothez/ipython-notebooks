{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import packages.helpers as hlp\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "from matplotlib import pyplot as plt\n",
    "import pymc as pm\n",
    "\n",
    "names = ['Kris Kroski', 'Eddie VanBogaert', 'Boaz Reisman', 'Brad Siefert', \n",
    "         'Kyle Gilbert', 'Richard Hankison', 'Vladimir Jornitski', 'Rachel Schneebaum',\n",
    "        'Frank Korf', 'Andrew Parnell', 'Andrew Weber']\n",
    "\n",
    "name = None\n",
    "\n",
    "room_strs = ['joined the room', 'left the room']\n",
    "docs = collections.defaultdict(list)\n",
    "day_index = 0\n",
    "index = 0\n",
    "dates = {}\n",
    "date_str = \"\"\n",
    "\n",
    "with open('data/hipchat_room','r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if any(name in line for name in names) and not any(room_str in line for room_str in room_strs):        \n",
    "            try:\n",
    "                name = re.sub(r'\\xc2\\xb7(.*?)$', '', line)\n",
    "            except:\n",
    "                continue\n",
    "        elif not any(room_str in line for room_str in room_strs) and ', 2015' not in line and name is not None:\n",
    "            #print \"{} -- {}\".format(day_index, line)\n",
    "            docs[name].append(hlp.prettify(line))\n",
    "            \n",
    "    \n",
    "\n",
    "#print dates\n",
    "#print len(docs)\n",
    "#indexes = docs.keys()\n",
    "#chat_count = [len(docs[i]) for i in range(indexes[0], indexes[len(indexes) - 1])]\n",
    "#lines = docs['Richard Hankison']\n",
    "#for line in lines:\n",
    "#    print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 628)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(['image', 'thumbnail', 'video', 'im', 'ive', 'ill', 'vladimirjornitski'])\n",
    "#print my_stop_words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words)\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs['Andrew Parnell'])\n",
    "\n",
    "#print docs['Eddie VanBogaert'][122]\n",
    "#print tfidf.toarray()[122]\n",
    "#print tfidf_vectorizer.get_feature_names()\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 2)\n",
      "628\n",
      "(2, 628)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "lsa = TruncatedSVD(2, algorithm = 'randomized')\n",
    "dtm_lsa = lsa.fit_transform(tfidf)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n",
    "\n",
    "print dtm_lsa.shape\n",
    "print len(tfidf_vectorizer.get_feature_names())\n",
    "print lsa.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0: \n",
      "hey\n",
      "guys\n",
      "meeting\n",
      "company\n",
      "just\n",
      "office\n",
      "bradsiefert\n",
      "everybody\n",
      "thanks\n",
      "11\n",
      "\n",
      "\n",
      "Concept 1: \n",
      "haha\n",
      "nice\n",
      "thats\n",
      "awesome\n",
      "lol\n",
      "great\n",
      "work\n",
      "right\n",
      "away\n",
      "thought\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://www.youtube.com/watch?v=BJ0MnawUpaU\n",
    "\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    comp_terms = zip(terms, comp)\n",
    "    sorted_terms = sorted(comp_terms, key= lambda x: x[1], reverse=True)[:10]\n",
    "    print \"Concept %d: \"%i\n",
    "    for term in sorted_terms:\n",
    "        print term[0]\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
